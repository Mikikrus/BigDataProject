{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67bb6d4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Project description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923f9c4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The project is about predicting the number of recommendations of a comment performed on New York Times Comments\n",
    "dataset that can be found under the link https://www.kaggle.com/datasets/aashita/nyt-comments.\n",
    "Main challanges of this project are:\n",
    "* handling large data volume\n",
    "* feature engineering\n",
    "* etc..\n",
    "To "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e0bda",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dbda11c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import DateType\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5bc858",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setMaster(\"local[8]\").setAppName(\"big_data\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f839f482",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09139b4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e246c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_spark_df(path):\n",
    "    return spark.read.option(\"multiline\",True).option('lineSep','\\n').option(\"header\", True).option(\"delimiter\", \",\").option(\"inferSchema\",True).csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e774e4e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "articles_df = read_spark_df('data/nyt-articles-2020.csv')\n",
    "comments_df = read_spark_df('data/nyt-comments-2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51e144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = comments_df.limit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "383a8da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[commentID: int, status: string, commentSequence: int, userID: int, userDisplayName: string, userLocation: string, userTitle: string, commentBody: string, createDate: string, updateDate: string, approveDate: string, recommendations: string, replyCount: string, editorsSelection: string, parentID: string, parentUserDisplayName: string, depth: string, commentType: string, trusted: string, recommendedFlag: int, permID: string, isAnonymous: string, articleID: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc0b4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = comments_df.withColumn(\"updateDate\", comments_df['updateDate'].cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cfd7ad1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- newsdesk: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- subsection: string (nullable = true)\n",
      " |-- material: string (nullable = true)\n",
      " |-- headline: string (nullable = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- keywords: string (nullable = true)\n",
      " |-- word_count: string (nullable = true)\n",
      " |-- pub_date: string (nullable = true)\n",
      " |-- n_comments: string (nullable = true)\n",
      " |-- uniqueID\\r: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "articles_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a182f3a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- commentID: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- commentSequence: integer (nullable = true)\n",
      " |-- userID: integer (nullable = true)\n",
      " |-- userDisplayName: string (nullable = true)\n",
      " |-- userLocation: string (nullable = true)\n",
      " |-- userTitle: string (nullable = true)\n",
      " |-- commentBody: string (nullable = true)\n",
      " |-- createDate: string (nullable = true)\n",
      " |-- updateDate: string (nullable = true)\n",
      " |-- approveDate: string (nullable = true)\n",
      " |-- recommendations: string (nullable = true)\n",
      " |-- replyCount: string (nullable = true)\n",
      " |-- editorsSelection: string (nullable = true)\n",
      " |-- parentID: string (nullable = true)\n",
      " |-- parentUserDisplayName: string (nullable = true)\n",
      " |-- depth: string (nullable = true)\n",
      " |-- commentType: string (nullable = true)\n",
      " |-- trusted: string (nullable = true)\n",
      " |-- recommendedFlag: integer (nullable = true)\n",
      " |-- permID: string (nullable = true)\n",
      " |-- isAnonymous: string (nullable = true)\n",
      " |-- articleID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f26f20",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can observe that although we used inferSchema some of the columns should be stored as a different data type. Let's fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e88b5eb5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comments_df=comments_df.withColumn('recommendations',comments_df['recommendations'].cast(\"float\"))\\\n",
    "                        .withColumn(\"createDate\", comments_df['createDate'].cast(DateType()))\\\n",
    "                        .withColumn(\"updateDate\", comments_df['updateDate'].cast(DateType()))\\\n",
    "                        .withColumn(\"approveDate\", comments_df['approveDate'].cast(DateType()))\\\n",
    "                        .withColumn('replyCount',comments_df['replyCount'].cast(\"int\"))\\\n",
    "                        .withColumn('depth',comments_df['depth'].cast(\"int\"))\\\n",
    "                        .withColumn('isAnonymous',comments_df['isAnonymous'].cast(\"int\"))\\\n",
    "                        .withColumn('editorsSelection',comments_df['editorsSelection'].cast(\"int\"))\n",
    "#actually some of the above columns are boolean but pyspark does not provide such datatype so we cast them to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "250dd532",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- commentID: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- commentSequence: integer (nullable = true)\n",
      " |-- userID: integer (nullable = true)\n",
      " |-- userDisplayName: string (nullable = true)\n",
      " |-- userLocation: string (nullable = true)\n",
      " |-- userTitle: string (nullable = true)\n",
      " |-- commentBody: string (nullable = true)\n",
      " |-- createDate: date (nullable = true)\n",
      " |-- updateDate: date (nullable = true)\n",
      " |-- approveDate: date (nullable = true)\n",
      " |-- recommendations: float (nullable = true)\n",
      " |-- replyCount: integer (nullable = true)\n",
      " |-- editorsSelection: integer (nullable = true)\n",
      " |-- parentID: string (nullable = true)\n",
      " |-- parentUserDisplayName: string (nullable = true)\n",
      " |-- depth: integer (nullable = true)\n",
      " |-- commentType: string (nullable = true)\n",
      " |-- trusted: string (nullable = true)\n",
      " |-- recommendedFlag: integer (nullable = true)\n",
      " |-- permID: string (nullable = true)\n",
      " |-- isAnonymous: integer (nullable = true)\n",
      " |-- articleID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e722cf5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's take a look at our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "987a22a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|  recommendations|\n",
      "+-------+-----------------+\n",
      "|  count|            10000|\n",
      "|   mean|          20.9887|\n",
      "| stddev|97.33120007767721|\n",
      "|    min|              0.0|\n",
      "|    max|           3816.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments_df.describe(['recommendations']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3220e527",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can observe that data is contains outliers. We will get rid of them using quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebf35abe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "upper_limit = comments_df.approxQuantile('recommendations', [ 0.9], 0.05)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e09f6899",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comments_df = comments_df.filter((col('recommendations')<upper_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c6e0d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|  recommendations|\n",
      "+-------+-----------------+\n",
      "|  count|             8512|\n",
      "|   mean|5.095277255639098|\n",
      "| stddev|5.478552516337315|\n",
      "|    min|              0.0|\n",
      "|    max|             23.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments_df.describe(['recommendations']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aca0447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|      createDateInt|\n",
      "+-------+-------------------+\n",
      "|  count|               8512|\n",
      "|   mean|1.577956250892857E9|\n",
      "| stddev|  419763.5688200801|\n",
      "|    min|         1577833200|\n",
      "|    max|         1601503200|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "comments_df=comments_df.withColumn(\"createDateInt\", F.unix_timestamp(comments_df['createDate']))\n",
    "comments_df.describe(['createDateInt']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee6be2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gre_histogram = comments_df.select('recommendations').rdd.flatMap(lambda x: x).histogram(11)\n",
    "\n",
    "# Loading the Computed Histogram into a Pandas Dataframe for plotting\n",
    "pd.DataFrame(\n",
    "    list(zip(*gre_histogram)), \n",
    "    columns=['bin', 'frequency']\n",
    ").set_index(\n",
    "    'bin'\n",
    ").plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc9bcd",
   "metadata": {},
   "source": [
    "Transformr text to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a3a9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.mllib.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4c72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77f4eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover,Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5af41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(df,column='commentBody'):\n",
    "    df = df.withColumn(column, trim(regexp_replace(column,'(@\\w+)|[^a-zA-Z\\s]', '')))\n",
    "    df = df.select(split(col(column),\" \").alias(column))\n",
    "    remover = StopWordsRemover(inputCol=column, outputCol=\"filtered\")\n",
    "    filtered = remover.transform(df)\n",
    "    word2vec = Word2Vec(inputCol=\"filtered\", outputCol=\"vector\")\n",
    "    model = word2vec.fit(filtered)\n",
    "    return model.transform(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7b7fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_vector(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "371118bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|         commentBody|            filtered|              vector|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[Here, is, someth...|[something, think...|[-0.0012416364657...|\n",
      "|[I, have, used, m...|[used, VA, loan, ...|[-0.0203269722743...|\n",
      "|[would, someone, ...|[someone, take, V...|[-0.0044137245160...|\n",
      "|[here, in, the, A...|[Alabama, PNW, tr...|[0.00108524933036...|\n",
      "|[just, a, guess, ...|[guess, doubt, cr...|[-0.0057377919769...|\n",
      "|[st, you, should,...|[st, take, note, ...|[-0.0123027005052...|\n",
      "|[SickBut, some, a...|[SickBut, action,...|[-0.0128891877830...|\n",
      "|[I, totally, agre...|[totally, agree, ...|[0.01775400146531...|\n",
      "|[Bill, Clinton, w...|[Bill, Clinton, p...|[0.00155126106284...|\n",
      "|[Being, on, the, ...|[board, long, tim...|[0.00329689623675...|\n",
      "|[until, you, get,...|      [get, elected]|[0.04873079177923...|\n",
      "|[This, is, a, ter...|[terrific, idea, ...|[0.01907857486512...|\n",
      "|[Barth, Oh, Jesu,...|[Barth, Oh, Jesu,...|[-0.0043864731821...|\n",
      "|[Barth, Hi, James...|[Barth, Hi, James...|[-0.0032263528072...|\n",
      "|[M, Tominey, Thin...|[M, Tominey, Thin...|[0.02825818654629...|\n",
      "|[What, I, dont, u...|[dont, understand...|[0.01022289061123...|\n",
      "|[The, accreditati...|[accreditation, p...|[-0.0052877632389...|\n",
      "|[Schwartz, The, A...|[Schwartz, Americ...|[-0.0051788782696...|\n",
      "|[A, whole, , lett...|[whole, , letters...|[-0.0070270372161...|\n",
      "|[Well, , what, ar...|[Well, , hundreds...|[0.01446733054971...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6ae1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments_df=comments_df.withColumn(\"createDateInt\",comments_df.createDateInt.cast('double'))\n",
    "# # df=df.withColumn(\"vector\",df.vector.cast('array<bigint>'))\n",
    "# df.withColumn(\n",
    "#     \"vector\", \n",
    "#     F.array_union(df.vector, F.array(comments_df.createDateInt))\n",
    "# ).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dde9fe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- commentID: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- commentSequence: integer (nullable = true)\n",
      " |-- userID: integer (nullable = true)\n",
      " |-- userDisplayName: string (nullable = true)\n",
      " |-- userLocation: string (nullable = true)\n",
      " |-- userTitle: string (nullable = true)\n",
      " |-- commentBody: string (nullable = true)\n",
      " |-- createDate: date (nullable = true)\n",
      " |-- updateDate: date (nullable = true)\n",
      " |-- approveDate: date (nullable = true)\n",
      " |-- recommendations: float (nullable = true)\n",
      " |-- replyCount: integer (nullable = true)\n",
      " |-- editorsSelection: integer (nullable = true)\n",
      " |-- parentID: string (nullable = true)\n",
      " |-- parentUserDisplayName: string (nullable = true)\n",
      " |-- depth: integer (nullable = true)\n",
      " |-- commentType: string (nullable = true)\n",
      " |-- trusted: string (nullable = true)\n",
      " |-- recommendedFlag: integer (nullable = true)\n",
      " |-- permID: string (nullable = true)\n",
      " |-- isAnonymous: integer (nullable = true)\n",
      " |-- articleID: string (nullable = true)\n",
      " |-- createDateInt: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e0bf65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(commentID=104387472, status='approved', commentSequence=104387472, userID=60215558, userDisplayName='magicisnotreal', userLocation='earth', userTitle=None, commentBody='Here is something I think is fraudulent that vets are subject to If you use your VA home loan option you have to pay higher interest rates regardless of your credit rating becuase supposedly it is more risky.How exactly is a guaranteed loan more risky than a not guaranteed commercial loan?', createDate=datetime.date(2020, 1, 1), updateDate=datetime.date(2020, 1, 1), approveDate=datetime.date(2020, 1, 1), recommendations=7.0, replyCount=5, editorsSelection=None, parentID=None, parentUserDisplayName=None, depth=1, commentType='comment', trusted='0', recommendedFlag=0, permID='104387472', isAnonymous=None, articleID='nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3ccbd', createDateInt=1577833200, commentBody=['Here', 'is', 'something', 'I', 'think', 'is', 'fraudulent', 'that', 'vets', 'are', 'subject', 'to', 'If', 'you', 'use', 'your', 'VA', 'home', 'loan', 'option', 'you', 'have', 'to', 'pay', 'higher', 'interest', 'rates', 'regardless', 'of', 'your', 'credit', 'rating', 'becuase', 'supposedly', 'it', 'is', 'more', 'riskyHow', 'exactly', 'is', 'a', 'guaranteed', 'loan', 'more', 'risky', 'than', 'a', 'not', 'guaranteed', 'commercial', 'loan'], filtered=['something', 'think', 'fraudulent', 'vets', 'subject', 'use', 'VA', 'home', 'loan', 'option', 'pay', 'higher', 'interest', 'rates', 'regardless', 'credit', 'rating', 'becuase', 'supposedly', 'riskyHow', 'exactly', 'guaranteed', 'loan', 'risky', 'guaranteed', 'commercial', 'loan'], vector=DenseVector([-0.0012, -0.0094, 0.0013, 0.0171, -0.0073, 0.0052, -0.003, -0.026, -0.0114, 0.0073, 0.0152, -0.0201, -0.0014, -0.0045, 0.0023, 0.0081, 0.0041, 0.0119, 0.0015, 0.0082, 0.009, -0.0051, 0.0236, 0.006, 0.0136, -0.0168, 0.0005, 0.0008, 0.0141, 0.0085, -0.0077, -0.0063, -0.001, 0.0028, 0.0068, 0.0041, 0.0087, 0.0071, 0.0153, 0.0026, -0.0224, -0.0071, -0.0109, 0.0008, 0.0077, -0.016, -0.0006, 0.0134, 0.0275, -0.0154, -0.0009, -0.0194, -0.0059, 0.0075, -0.0095, 0.0025, -0.001, -0.0014, -0.0099, 0.0106, -0.0015, 0.0061, 0.0115, -0.003, 0.0197, -0.0082, 0.021, -0.0028, 0.0044, -0.0059, -0.0042, 0.0047, 0.0064, 0.0022, 0.0039, 0.018, 0.0253, -0.0028, 0.015, -0.0083, -0.0001, 0.011, -0.0207, -0.0215, 0.0049, 0.0045, 0.0092, 0.0234, -0.0001, -0.0128, -0.0091, 0.0043, 0.0106, -0.0271, 0.0163, 0.0028, 0.0189, 0.0105, 0.0004, 0.0066]))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "df=df.withColumn('row_index', row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "comments_df=comments_df.withColumn('row_index', row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "# df = df.join(comments_df, on=[\"row_index\"]).drop(\"row_index\")\n",
    "comments_df = comments_df.join(df, on=[\"row_index\"]).drop(\"row_index\")\n",
    "comments_df.take(1)\n",
    "#comments_df = comments_df.withColumnRenamed(\"commentBody_filtered\",\"commentBody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9c6d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "numericCols = ['vector', 'createDateInt']\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
    "comments_df = assembler.transform(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "185c945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "bucketizer = Bucketizer(splits=[ 0, 6, 12, 18, float('Inf') ],inputCol=\"recommendations\", outputCol=\"buckets\")\n",
    "comments_df = bucketizer.setHandleInvalid(\"keep\").transform(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea2f5c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           buckets|\n",
      "+-------+------------------+\n",
      "|  count|              8512|\n",
      "|   mean|0.5236137218045113|\n",
      "| stddev|0.8470961020589826|\n",
      "|    min|               0.0|\n",
      "|    max|               3.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(commentID=104387472, status='approved', commentSequence=104387472, userID=60215558, userDisplayName='magicisnotreal', userLocation='earth', userTitle=None, commentBody='Here is something I think is fraudulent that vets are subject to If you use your VA home loan option you have to pay higher interest rates regardless of your credit rating becuase supposedly it is more risky.How exactly is a guaranteed loan more risky than a not guaranteed commercial loan?', createDate=datetime.date(2020, 1, 1), updateDate=datetime.date(2020, 1, 1), approveDate=datetime.date(2020, 1, 1), recommendations=7.0, replyCount=5, editorsSelection=None, parentID=None, parentUserDisplayName=None, depth=1, commentType='comment', trusted='0', recommendedFlag=0, permID='104387472', isAnonymous=None, articleID='nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3ccbd', createDateInt=1577833200, commentBody=['Here', 'is', 'something', 'I', 'think', 'is', 'fraudulent', 'that', 'vets', 'are', 'subject', 'to', 'If', 'you', 'use', 'your', 'VA', 'home', 'loan', 'option', 'you', 'have', 'to', 'pay', 'higher', 'interest', 'rates', 'regardless', 'of', 'your', 'credit', 'rating', 'becuase', 'supposedly', 'it', 'is', 'more', 'riskyHow', 'exactly', 'is', 'a', 'guaranteed', 'loan', 'more', 'risky', 'than', 'a', 'not', 'guaranteed', 'commercial', 'loan'], filtered=['something', 'think', 'fraudulent', 'vets', 'subject', 'use', 'VA', 'home', 'loan', 'option', 'pay', 'higher', 'interest', 'rates', 'regardless', 'credit', 'rating', 'becuase', 'supposedly', 'riskyHow', 'exactly', 'guaranteed', 'loan', 'risky', 'guaranteed', 'commercial', 'loan'], vector=DenseVector([-0.0012, -0.0094, 0.0013, 0.0171, -0.0073, 0.0052, -0.003, -0.026, -0.0114, 0.0073, 0.0152, -0.0201, -0.0014, -0.0045, 0.0023, 0.0081, 0.0041, 0.0119, 0.0015, 0.0082, 0.009, -0.0051, 0.0236, 0.006, 0.0136, -0.0168, 0.0005, 0.0008, 0.0141, 0.0085, -0.0077, -0.0063, -0.001, 0.0028, 0.0068, 0.0041, 0.0087, 0.0071, 0.0153, 0.0026, -0.0224, -0.0071, -0.0109, 0.0008, 0.0077, -0.016, -0.0006, 0.0134, 0.0275, -0.0154, -0.0009, -0.0194, -0.0059, 0.0075, -0.0095, 0.0025, -0.001, -0.0014, -0.0099, 0.0106, -0.0015, 0.0061, 0.0115, -0.003, 0.0197, -0.0082, 0.021, -0.0028, 0.0044, -0.0059, -0.0042, 0.0047, 0.0064, 0.0022, 0.0039, 0.018, 0.0253, -0.0028, 0.015, -0.0083, -0.0001, 0.011, -0.0207, -0.0215, 0.0049, 0.0045, 0.0092, 0.0234, -0.0001, -0.0128, -0.0091, 0.0043, 0.0106, -0.0271, 0.0163, 0.0028, 0.0189, 0.0105, 0.0004, 0.0066]), features=DenseVector([-0.0012, -0.0094, 0.0013, 0.0171, -0.0073, 0.0052, -0.003, -0.026, -0.0114, 0.0073, 0.0152, -0.0201, -0.0014, -0.0045, 0.0023, 0.0081, 0.0041, 0.0119, 0.0015, 0.0082, 0.009, -0.0051, 0.0236, 0.006, 0.0136, -0.0168, 0.0005, 0.0008, 0.0141, 0.0085, -0.0077, -0.0063, -0.001, 0.0028, 0.0068, 0.0041, 0.0087, 0.0071, 0.0153, 0.0026, -0.0224, -0.0071, -0.0109, 0.0008, 0.0077, -0.016, -0.0006, 0.0134, 0.0275, -0.0154, -0.0009, -0.0194, -0.0059, 0.0075, -0.0095, 0.0025, -0.001, -0.0014, -0.0099, 0.0106, -0.0015, 0.0061, 0.0115, -0.003, 0.0197, -0.0082, 0.021, -0.0028, 0.0044, -0.0059, -0.0042, 0.0047, 0.0064, 0.0022, 0.0039, 0.018, 0.0253, -0.0028, 0.015, -0.0083, -0.0001, 0.011, -0.0207, -0.0215, 0.0049, 0.0045, 0.0092, 0.0234, -0.0001, -0.0128, -0.0091, 0.0043, 0.0106, -0.0271, 0.0163, 0.0028, 0.0189, 0.0105, 0.0004, 0.0066, 1577833200.0]), buckets=1.0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.describe(['buckets']).show()\n",
    "comments_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3659b2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+--------------------+\n",
      "|predictedLabel|buckets|            features|\n",
      "+--------------+-------+--------------------+\n",
      "|           0.0|    2.0|[-0.0203269722743...|\n",
      "|           0.0|    1.0|[-0.0044137245160...|\n",
      "|           0.0|    0.0|[0.00155126106284...|\n",
      "|           0.0|    1.0|[-0.0069727705781...|\n",
      "|           0.0|    1.0|[-0.0134414144179...|\n",
      "|           0.0|    1.0|[-4.5931638361742...|\n",
      "|           0.0|    2.0|[-0.0070270372161...|\n",
      "|           0.0|    1.0|[-0.0032263528072...|\n",
      "|           0.0|    0.0|[-0.0133554951101...|\n",
      "|           0.0|    1.0|[0.00158347106097...|\n",
      "|           0.0|    1.0|[-0.0299132053359...|\n",
      "|           0.0|    0.0|[-0.0029049653156...|\n",
      "|           0.0|    1.0|[0.01227360839645...|\n",
      "|           0.0|    3.0|[-0.0086663363401...|\n",
      "|           0.0|    1.0|[-0.0092189190320...|\n",
      "+--------------+-------+--------------------+\n",
      "only showing top 15 rows\n",
      "\n",
      "Test Error = 0.357727\n",
      "RandomForestClassificationModel: uid=RandomForestClassifier_b447aad870e0, numTrees=20, numClasses=4, numFeatures=101\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = comments_df\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"buckets\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\").fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"buckets\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"buckets\", \"features\").show(15)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"buckets\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9cf2e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prediction'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfModel.getPredictionCol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d181518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
